[<img src="https://img.shields.io/badge/powered%20by-OpenCitations-%239931FC?labelColor=2D22DE" />](http://opencitations.net)
[![Run tests](https://github.com/opencitations/ra_processor/actions/workflows/run_tests.yml/badge.svg)](https://github.com/opencitations/oc_meta/actions/workflows/run_tests.yml)
![Coverage](https://raw.githubusercontent.com/opencitations/ra_processor/main/test/coverage/coverage.svg)
<!-- ![PyPI](https://img.shields.io/pypi/pyversions/oc_meta) -->
![GitHub code size in bytes](https://img.shields.io/github/languages/code-size/opencitations/ra_processor)

# OpenCitations Data Sources Converter

This repository contains scripts for converting scholarly bibliographic metadata from various data sources into the format accepted by OpenCitations Meta. The data sources currently supported are:
- Crossref
- DataCite
- PubMed
- OpenAIRE
- JaLC
- mEDRA


<!-- TABLE OF CONTENTS -->
  <summary><h2 style="display: inline-block">Table of Contents</h2></summary>
  <ol>
    <li><a href="#about-the-project">About The Project</a></li>
    <li><a href="#components">Software Components</a></li>
    <li><a href="#validation">ID Validation Process</a></li>
    <li><a href="#run">How to Run the Softwares</a></li>
    <li><a href="#extend">How to Extend the Software</a></li>
    <li><a href="#license">License</a></li>
    <li><a href="#contact">Contact</a></li>
    <li><a href="#acknowledgements">Acknowledgements</a></li>
    <li><a href="#references">References</a></li>
  </ol>


<!-- ABOUT THE PROJECT -->
## About The Project

The main function of this software is to perform a metadata crosswalk between the data sources providing bibliographic and citation data and the [OpenCitations Data Model (OCDM)](https://opencitations.net/model). At the same time, the software also handles the normalization and validation of the identifiers provided by the data source in all cases where it is not also the registration agency for those identifiers. The software generates **two main output datasets**, based on the data provided by a specific source:

- **Bibliographic entities CSV tables**;
  which are meant to be used as input for the [META software](https://github.com/opencitations/oc_meta.git), an OpenCitations tool and database for managing bibliographic entities' metadata. Example:

| id                             | title                                                | author                                               | pub_date  | venue                                       | volume | issue | page   | type           | publisher                                      | editor |
|--------------------------------|------------------------------------------------------|------------------------------------------------------|-----------|---------------------------------------------|--------|-------|--------|----------------|------------------------------------------------|--------|
| doi:10.9799/ksfan.2012.25.1.069 | Nonthermal Sterilization and Shelf-life Extension of Seafood Products by Intense Pulsed Light Treatment | Cheigh, Chan-Ick [orcid:0000-0002-6227-4053]; Mun, Ji-Hye [orcid:0000-0002-6227-4053]; Chung, Myong-Soo | 2012-3-31 | The Korean Journal of Food And Nutrition [issn:1225-4339] | 25     | 1     | 69-76  | journal article | The Korean Society of Food and Nutrition [crossref:4768] |        |

- **AnyID-to-Any-ID citations CSV tables**;
  which will be used as input for the [INDEX software](https://github.com/opencitations/index), an OpenCitations tool and database for producing and managing citations between bibliographic entities identified by OMIDs (internal and unique identifiers assigned by OpenCitations). Example:

| citing                          | cited                        |
|---------------------------------|------------------------------|
| doi:10.11426/nagare1970.2.4_1   | doi:10.1295/kobunshi.16.921  |


In practice, the outputs generated by `oc_ds_converter` are used in subsequent steps of the data ingestion process within the OpenCitations infrastructure. Specifically, the metadata tables are used as input for META. The software assigns an OMID identifier to new entities and propagates an existing OMID to the entities already present in the OpenCitations databases, thereby deduplicating identical entities ingested from different data sources.

Subsequently, the INDEX software, responsible for producing citation data compliant with the OpenCitations data model, takes as input the anyID-to-anyID citation tables produced by the `oc_ds_converter` software. It queries the META database to retrieve the OMID associated with each entity's identifier and produces OMID-to-OMID citations in various formats (RDF, SCHOLIX, CSV) as output.

Here, a diagram of the OpenCitations ingestion workflow:
![OpenCitations Ingestion Workflow](https://github.com/ariannamorettj/OC_documents/blob/5115cf039b4baa2319c6c22cc270647861ae2f5a/ingestion_workflow_overview.jpg)

<!-- SOFTWARE COMPONENTS -->
## Software Components
The software is built upon three fundamental components, each addressing specific needs: 
1. Metadata Crosswalk (oc_ds_converter) 
2. Identifier Validation (oc_ds_converter/oc_idmanager) 
3. Data Storage Management (oc_ds_converter/oc_idmanager/oc_data_storage) 
### Metadata Crosswalk (oc_ds_converter)
Within this layer, there is a specific plugin for each data source, which, in turn, contains a Python file (usually named after the data source + "_ processing.py," e.g., oc_ds_converter/datacite/datacite_processing.py). In this file, a class is defined to convert metadata provided by the specific source into metadata compliant with OCDM. For example, in the file datacite_processing.py, the class DataciteProcessing(RaProcessor) is defined, which contains the method `csv_creator(self, item: dict) -> dict`. This method is responsible for producing a dictionary of metadata representing a bibliographic entity extracted from the dump provided by DataCite. 
### Identifier Validation (oc_ds_converter/oc_idmanager)
This software validates all identifiers not provided by the identifier registration agency itself. Currently, the identifiers handled by OpenCitations are: 
1. [DOI]()
2. PMID
3. PMC
4. VIAF
5. WIKIDATA
6. WIKIPEDIA
7. ROR
8. ORCID
9. ARXIV
10. JID
11. ISSN
12. ISBN
13. URL

Each identifier schema has its own class (e.g.: PMIDManager(IdentifierManager), defined in oc_ds_converter/oc_idmanager/pmid.py), instantiated according to the model provided by the abstract class IdentifierManager(metaclass=ABCMeta), in oc_ds_converter/oc_idmanager/base.py. 
Each class provides methods for normalising the id string, checking the correctness of the id syntax, and verifying its existence using its specific API service. 
### Data Storage Management (oc_ds_converter/oc_idmanager/oc_data_storage) 
OpenCitations ds_converter currently offers three storage systems, which can be alternatively used: 
1. In Memory (class InMemoryStorageManager(StorageManager), defined in oc_ds_converter/oc_idmanager/oc_data_storage/in_memory_manager.py)
2. Redis (class RedisStorageManager(StorageManager), defined in oc_ds_converter/oc_idmanager/oc_data_storage/redis_manager.py)
3. Sqlite (class SqliteStorageManager(StorageManager), defined in oc_ds_converter/oc_idmanager/oc_data_storage/sqlite_manager.py). 
Each of these classes is defined as an instance of the abstract class StorageManager(metaclass=ABCMeta), defined in oc_ds_converter/oc_idmanager/oc_data_storage/storage_manager.py. 

The type of storage manager used for a specific data source process can be chosen by the user (however, we suggest using the Redis Storage Manager). 
An instance of the chosen storage manager will be used by all the ID Managers instantiated in the process to store validation data at the end of each data chunk management. 
The temporary storage manager used while processing a data chunk is instead always an instance of the In-Memory storage manager (which is based on the use of a JSON dictionary). The reason for this choice lies in the fact that, in case of a run stop, the execution would restart processing from the beginning of the chunk that was being managed at the time of the interruption, and thus the data already memorized by a redis or sqlite storage manager would be duplicated, while the data memorized in an instance of an in-memory storage manager are just lost and reprocessed. 

<!-- ID VALIDATION PROCESS -->
## ID Validation Process 
In order to avoid redundant API checks, we rely on an ad-hoc data storage system. More in detail, in case the data source is also the id registration agency of at least a part of the identifiers provided in a data dump, we perform a full preliminary iteration of the data to store these identifiers as valid, without any further check. 

![Perliminary data dump iteration](https://github.com/ariannamorettj/OC_documents/blob/5115cf039b4baa2319c6c22cc270647861ae2f5a/id_validation_pre_process_dump_iteration_diagram.png) 

Subsequently, we perform another full iteration, validating all identifiers not registered by the data source itself. 

![Data dump iteration for data validation](https://github.com/ariannamorettj/OC_documents/blob/5115cf039b4baa2319c6c22cc270647861ae2f5a/id_validation_process_dump_iteration_diagram.png) 

Note that, to manage the large amount of data provided by each data source, the input dataset is generally divided into data chunks. As mentioned above, in order to avoid data duplication in case of a process interruption and restart, data concerning each chunk are temporarily stored in an instance of the in-memory storage manager (see InMemoryStorageManager(StorageManager) in oc_ds_converter/oc_idmanager/oc_data_storage/in_memory_manager.py). The data stored in the temporary storage manager is transferred to the main storage manager (containing the ID validation data of the full input dataset) at the end of the chunk's process, when both the CSV tables concerning bibliographic metadata and citations are produced.
For each encountered identifier to be validated, an ordered list of checks should be performed, stopping as soon as the validity value can be assessed:
1. Search for the identifier in the in-memory storage manager, containing data concerning the current data chunk; 
2. Search for the identifier in the main storage manager, containing data concerning the whole dataset; 
3. Search for the identifier in the OpenCitations databases, containing data of all the datasets ever ingested in OpenCitations.
4. Use ID-schema specific API services to retrieve the validity information of the ID. 

<!-- LICENSE -->
## License

Distributed under the ISC License. See `LICENSE` for more information.


<!-- CONTACTS -->
## Contacts

#### Authors and Current maintainers of the repository

- Arianna Moretti - [@ariannamorettj](https://github.com/ariannamorettj) - arianna.moretti4@unibo.it
- Arcangelo Massari - [@arcangelo7](https://github.com/arcangelo7) - arcangelo.massari@unibo.it
- Elia Rizzetto - [@eliarizzetto](https://github.com/eliarizzetto) - elia.rizzetto@studio.unibo.it
- Marta Soricetti - [@martasoricetti](https://github.com/martasoricetti) - marta.soricetti@studio.unibo.it

Project Link: [https://github.com/opencitations/oc_ds_converter](https://github.com/opencitations/oc_ds_converter)


<!-- ACKNOWLEDGEMENTS -->
## Acknowledgements
This project has been developed under the supervision of Prof. Silvio Peroni.
- Silvio Peroni - [@essepuntato](https://github.com/essepuntato) - silvio.peroni@unibo.it

<!-- REFERENCES -->
## References
- [The OpenCitations Data Model](https://link.springer.com/chapter/10.1007/978-3-030-62466-8_28)
- [OpenCitations Meta](https://doi.org/10.48550/arXiv.2306.16191)

<!-- MARKDOWN LINKS & IMAGES -->
<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->

